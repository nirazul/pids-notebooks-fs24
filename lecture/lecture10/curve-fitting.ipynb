{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2fa732-f11e-4b58-a4c1-c4ba64bdf1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b0c96a-13fe-40c9-80a4-fdbdbc00073c",
   "metadata": {},
   "source": [
    "# Curve fitting\n",
    "\n",
    "\n",
    "This notebook illustrates linear basis function models. By experimenting with the code, you can explore the following aspects of these models:\n",
    "\n",
    "* How different basis functions yield different predictions\n",
    "* How complex models may explain noise instead of just the underlying pattern\n",
    "* The effect of regularization\n",
    "* Making predictions with uncertainty by defining prior distributions on the parameters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9fe761",
   "metadata": {},
   "source": [
    "### Synthetic Data\n",
    "\n",
    "We generate synthetic data to which we fit the models. The data-generating function is $(f(x) = \\sin(2 \\pi x) + 1)$. Normally distributed noise $N(0, \\beta)$ is added to the generated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5a7f63-91ea-476d-92f1-1a2e676aa957",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "beta = 0.2\n",
    "\n",
    "xs = np.array([-1.0, -0.9, -0.8, -0.75, -0.1, 0.1, 0.2, 0.3, 0.5, 0.8, 0.9, 1.0])\n",
    "\n",
    "\n",
    "def true_fun(xs):\n",
    "    return np.sin(2 * math.pi * xs) + 1\n",
    "\n",
    "\n",
    "ys = true_fun(xs) + stats.norm(0, beta).rvs(len(xs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a18e82-2e8e-42ca-9238-6d35eca9868b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(xs, ys, 'o')\n",
    "plt.ylim([-2, 4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9f6b8f-38fa-42f6-b59e-a25d54db77c6",
   "metadata": {},
   "source": [
    "## Linear Basis Function Models\n",
    "\n",
    "The following function takes a list of basis functions and the data, \n",
    "and computes the parameters of the model. The parameters are calculated by simply solving the normal equations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de4e707-bab2-4f02-988b-0e34245420f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def solve_regression(basis_functions, xs, ys):\n",
    "    \"\"\" takes a list of basis_functions as well as the training data (xs, ys) and solves the \n",
    "        corresponding regression problem using the normal equation \"\"\"\n",
    "    m = len(basis_functions)\n",
    "\n",
    "    # Matrix containing the basis functions evaluated at the input points\n",
    "    Phi = np.zeros((len(xs), m))\n",
    "    for j in range(0, m):\n",
    "        Phi[:, j] = basis_functions[j](xs)\n",
    "\n",
    "    # small additional regularization term to improve numerical stability\n",
    "    reg = 1e-10 * np.eye(len(basis_functions))\n",
    "    w = np.linalg.inv(Phi.transpose() @ Phi + reg) @ Phi.transpose()\n",
    "\n",
    "    return w @ ys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1a7be2",
   "metadata": {},
   "source": [
    "The following function is used to plot the solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a44531-c133-48f1-99b1-a6962dd26605",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_solution(w, basis_functions, xs, ys, show_basis=True, show_gt=True):\n",
    "    \"\"\"\n",
    "    plots the basis function and the solutions for the (fitted) parameters w.\n",
    "    xs and ys contain the data. \n",
    "    The parameter show_gt and show_basis determine whether the ground truth \n",
    "    and basis functions are plotted. \n",
    "    \"\"\"\n",
    "    # plot in the interval -1, 1\n",
    "    x_values = np.linspace(-1, 1, 200)\n",
    "    y_values = np.zeros(len(xs))\n",
    "\n",
    "    # Compute the solution\n",
    "    Phi = np.zeros((len(x_values), len(basis_functions)))\n",
    "    for j in range(0, len(basis_functions)):\n",
    "        Phi[:, j] = basis_functions[j](x_values)\n",
    "    y_values = Phi @ w\n",
    "\n",
    "    # Plot the best prediction\n",
    "    plt.plot(xs, ys, 'o')\n",
    "    plt.plot(x_values, y_values, 'k', label=\"predicted\")\n",
    "\n",
    "    # Plot the basis fucntions\n",
    "    if show_basis:\n",
    "        for j in range(0, len(basis_functions)):\n",
    "            plt.plot(x_values, basis_functions[j](x_values) * w[j], ':', color=\"grey\")\n",
    "\n",
    "    if show_gt:\n",
    "        plt.plot(x_values, true_fun(x_values), '--r', label=\"ground truth\")\n",
    "\n",
    "    plt.xlabel(\"X\")\n",
    "    plt.ylabel(\"Y\")\n",
    "    plt.ylim([-2, 4])\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e54140",
   "metadata": {},
   "source": [
    "Let's experiment with some polynomials:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e852a90-d3cc-4e0c-9a65-8de75326f4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 15\n",
    "basis_functions = [lambda x, i=i: np.power(x, i) for i in list(range(0, m + 1))]\n",
    "ws = solve_regression(basis_functions, xs, ys)\n",
    "plot_solution(ws, basis_functions, xs, ys, show_gt=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9734f6e9",
   "metadata": {},
   "source": [
    "Radial basis function are local basis functions and have better properties than \n",
    "polynomials. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d03981-7cd0-4be5-918a-7e88b3591142",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 0.05\n",
    "basis_functions = [lambda x, mu=mu: np.exp(-np.power(x - mu, 2) / s) for mu in xs]\n",
    "ws = solve_regression(basis_functions, xs, ys)\n",
    "plot_solution(ws, basis_functions, xs, ys, show_gt=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef2b68c-0ae7-4ddf-9cba-9451f3455644",
   "metadata": {},
   "source": [
    "### Prefering simple solutions: Ridge regression\n",
    "\n",
    "To enforce simple solutions that do not learn the noise even with flexible models (many basis functions), we penalize solutions where the parameters are large. Thus, we solve $\\min_w \\sum_{i=0}^n (f(x_i,w)-y_i) + \\alpha \\| w \\|^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57b5d03-f106-4635-ad28-3af19be557d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def solve_regression_ridge(basis_functions, xs, ys, alpha):\n",
    "    \"\"\" takes a list of basis_functions as well as the training data (xs, ys) and solves the \n",
    "        corresponding regression problem using least squares regression \"\"\"\n",
    "    m = len(basis_functions)\n",
    "    Phi = np.zeros((len(xs), m))\n",
    "    for j in range(0, m):\n",
    "        Phi[:, j] = basis_functions[j](xs)\n",
    "    w = np.linalg.inv(Phi.transpose() @ Phi + alpha * np.eye(len(basis_functions))) @ Phi.transpose()\n",
    "\n",
    "    return w @ ys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8432c935",
   "metadata": {},
   "source": [
    "Let's play with the regularization parameter $\\alpha$ and observe what is happening to the \n",
    "basis functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f06026-b3a6-4e3c-a677-4f0314ee4ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 0.05\n",
    "alpha = 1e-1\n",
    "basis_functions = [lambda x, mu=mu: np.exp(-np.power(x - mu, 2) / s) for mu in xs]\n",
    "ws = solve_regression_ridge(basis_functions, xs, ys, alpha)\n",
    "plot_solution(ws, basis_functions, xs, ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a901f39",
   "metadata": {},
   "source": [
    "### Regression using neural networks\n",
    "\n",
    "Finally, we are using a neural network to fit the data. We are not implementing that ourselves, but using scikit learn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ce4d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfbe8bc8",
   "metadata": {},
   "source": [
    "We define a Neural Network using a hidden layer of size 20 and and 'tanh' as an activation function. We specify the number of iterations for the optimizer. A tolerance of 0 tells the\n",
    "optimizer not to stop before the maximum number of iterations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d77308",
   "metadata": {},
   "outputs": [],
   "source": "regr = MLPRegressor(hidden_layer_sizes=(20,), activation='tanh', tol=0, max_iter=30000)"
  },
  {
   "cell_type": "markdown",
   "id": "21756856",
   "metadata": {},
   "source": [
    "The input to the `fit` function of the regression is a 2D array, with the individual training examples in the rows. We reshape our original data and call the `fit` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cff1672",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs_array = np.array(xs).reshape((len(xs), 1))\n",
    "regr.fit(xs_array, ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1cf90d",
   "metadata": {},
   "source": [
    "We plot the result to see how the neural network does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560fceb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_vals = np.linspace(-1, 1, 100).reshape((100, 1))\n",
    "plt.plot(xs, ys, 'o')\n",
    "plt.plot(x_vals, regr.predict(x_vals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed07a6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedb7c14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-env-.conda-python_pids_2024-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
