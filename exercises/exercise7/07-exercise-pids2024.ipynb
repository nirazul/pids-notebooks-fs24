{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1f4e336",
   "metadata": {},
   "source": [
    "# Exercise sheet 7\n",
    "**Hello everyone!**\n",
    "\n",
    "**Points: 15**\n",
    "\n",
    "Topics of this exercise sheet are:\n",
    "* Probabilities\n",
    "* Law of large numbers\n",
    "* Central limit theorem\n",
    "\n",
    "\n",
    "Please let us know if you have questions or problems! <br>\n",
    "Contact us during the exercise session or on [Piazza](https://piazza.com/unibas.ch/spring2024/63982).\n",
    "\n",
    "**Automatic Feedback**\n",
    "\n",
    "This notebook can be automatically graded using Otter grader. To find how many points you get, simply run `grader.check_all()` from a new cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "657e1ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import bernoulli, norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b796e44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"07-exercise-pids2024.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43f1e5e",
   "metadata": {},
   "source": [
    "## 1) Central limit theorem (8 points)\n",
    "The central limit theorem is a key results of practical importance for data scientists. In this first part, we will work around this result to better understand it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e16d0d9",
   "metadata": {},
   "source": [
    "\n",
    "Let's start with the simplest statistical example, the toss of a coin. We simulate the toss using the generation of a Bernoulli random variable in the library scipy. We display the empirical distribution (histogram) of the generated samples. Let's call the sample size $N$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d25ed80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([506.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 494.]),\n",
       " array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "N=1000\n",
    "toss_coin = bernoulli.rvs(p=0.5,size=N) \n",
    "plt.hist(toss_coin)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3974401",
   "metadata": {},
   "source": [
    "### 1a (2 points)\n",
    "Reproduce this experiment $M$ times. Store the result in an array `toss_coin_all` of **size (M,N)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c836c252",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9faaf668e859520f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class Question1a:\n",
    "    M=1000\n",
    "    \n",
    "    toss_coin_all = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47330f7a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong style='color: red;'><pre style='display: inline;'>Question 1a</pre> results:</strong></p><p><strong><pre style='display: inline;'>Question 1a - 1</pre> result:</strong></p><pre>    ❌ Test case failed\n",
       "    Error at line 13 in test Question 1a:\n",
       "          assert_equal(toss_coin_all.shape, (M, N))\n",
       "    AttributeError: ellipsis' object has no attribute 'shape</pre>"
      ],
      "text/plain": [
       "Question 1a results:\n",
       "    Question 1a - 1 result:\n",
       "        ❌ Test case failed\n",
       "        Error at line 13 in test Question 1a:\n",
       "              assert_equal(toss_coin_all.shape, (M, N))\n",
       "        AttributeError: ellipsis' object has no attribute 'shape"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"Question 1a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ded77d8",
   "metadata": {},
   "source": [
    "### 1b (1 point)\n",
    "For each of the $M=1000$ experiment, compute the sum of the obtained values. Store the result in an array named `toss_sum`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f894cea9",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-43a0a0442ecf9f4c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class Question1b:\n",
    "    M = Question1a.M\n",
    "    toss_coin_all = Question1a.toss_coin_all\n",
    "    \n",
    "    toss_sum = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3cea7a29",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong style='color: red;'><pre style='display: inline;'>Question 1b</pre> results:</strong></p><p><strong><pre style='display: inline;'>Question 1b - 1</pre> result:</strong></p><pre>    ❌ Test case failed\n",
       "    Error at line 13 in test Question 1b:\n",
       "          assert_equal(toss_sum.shape[0], M)\n",
       "    AttributeError: ellipsis' object has no attribute 'shape</pre>"
      ],
      "text/plain": [
       "Question 1b results:\n",
       "    Question 1b - 1 result:\n",
       "        ❌ Test case failed\n",
       "        Error at line 13 in test Question 1b:\n",
       "              assert_equal(toss_sum.shape[0], M)\n",
       "        AttributeError: ellipsis' object has no attribute 'shape"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"Question 1b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef73f0c",
   "metadata": {},
   "source": [
    "### 1c (1 point) \n",
    "Then, display the histogram of this result, using `plt.hist` using **15 bins**. Make sure you plot it as a density (I.e. the area of the histogram sums to 1 (*see hint*) by choosing the right parameters. Assign the plot to the variable `density_plot`.\n",
    "\n",
    "Hint: [Examples using: matplotlib.pyplot.hist](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.hist.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4bce2a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: Question 1c        # (required) the path to a requirements.txt file\n",
    "manual: true     # whether this is a manually-graded question\n",
    "points: 2      # how many points this question is worth; defaults to 1 internally\n",
    "check_cell: false  # whether to include a check cell after this question (for autograded questions only)\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c156ca79",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Question1c:\n",
    "    toss_sum = Question1b.toss_sum\n",
    "    \n",
    "    density_plot = ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa4a60e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong style='color: red;'><pre style='display: inline;'>Question 1c</pre> results:</strong></p><p><strong><pre style='display: inline;'>Question 1c - 1</pre> result:</strong></p><pre>    ❌ Test case failed\n",
       "    Error at line 12 in test Question 1c:\n",
       "        area_under_curve = np.sum(density_plot[0] * (density_plot[1][1] - density_plot[1][0]))\n",
       "    TypeError: ellipsis' object is not subscriptable</pre>"
      ],
      "text/plain": [
       "Question 1c results:\n",
       "    Question 1c - 1 result:\n",
       "        ❌ Test case failed\n",
       "        Error at line 12 in test Question 1c:\n",
       "            area_under_curve = np.sum(density_plot[0] * (density_plot[1][1] - density_plot[1][0]))\n",
       "        TypeError: ellipsis' object is not subscriptable"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"Question 1c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3eb2f1",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "### 1d (2 point)\n",
    "Now we want to fit a Gaussian distribution to the samples in the previsous part. In particualr, we want to fit a Gaussian distribution to the following random variable:\n",
    "\n",
    "$$\n",
    " S_N = \\sum_{i = 1}^N X_i\n",
    "$$\n",
    "As mentioned in the lecture, the probablity distribution of $S_N$ tends to a Gaussian distribution as N goes to infinity:\n",
    "$$\n",
    " S_N \\to \\mathcal{N}(N \\mu, N \\sigma^2)\n",
    "$$\n",
    "Now, **display the probability density function (pdf) of the Gaussian random variable.** The mean ($\\mu$) and standard deviation ($\\sigma$) of the *Bernouli distribution* are:\n",
    "\n",
    "- $N$, the number of samples (1000)\n",
    "- $\\mu = 0.5$\n",
    "- $\\sigma = 0.5$\n",
    "\n",
    "Please use the variable `x` defined below as the x-axis of your plot. Name the plot `gaussian_plot`. Please use the scipy library and the example in this webpage: https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.norm.html."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3dd1fbb",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: Question 1d        # (required) the path to a requirements.txt file\n",
    "manual: true     # whether this is a manually-graded question\n",
    "points: 2      # how many points this question is worth; defaults to 1 internally\n",
    "check_cell: false  # whether to include a check cell after this question (for autograded questions only)\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7559022",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-78fc29e914b773a4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class Question1d:\n",
    "    from scipy.stats import norm # Please do not modify this line\n",
    "    \n",
    "    mu = 0.5\n",
    "    sigma = 0.5\n",
    "    x = np.linspace(norm.ppf(0.01, N * mu, np.sqrt(N) * sigma),\n",
    "                    norm.ppf(0.99, N * mu, np.sqrt(N) * sigma),\n",
    "                    N)\n",
    "    \n",
    "    gaussian_plot = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f78cc56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong style='color: red;'><pre style='display: inline;'>Question 1d</pre> results:</strong></p><p><strong><pre style='display: inline;'>Question 1d - 1</pre> result:</strong></p><pre>    ❌ Test case failed\n",
       "    Error at line 12 in test Question 1d:\n",
       "        assert_true(0 <= gaussian_plot[0].axes.get_ylim()[1] <= 1)\n",
       "    TypeError: ellipsis' object is not subscriptable</pre>"
      ],
      "text/plain": [
       "Question 1d results:\n",
       "    Question 1d - 1 result:\n",
       "        ❌ Test case failed\n",
       "        Error at line 12 in test Question 1d:\n",
       "            assert_true(0 <= gaussian_plot[0].axes.get_ylim()[1] <= 1)\n",
       "        TypeError: ellipsis' object is not subscriptable"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"Question 1d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b37455f",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "### 1e (2 points)\n",
    "Display the empirical distribution of the sum of tossed coins and the pdf of the Gaussian random variable on the same plot. Please use the variable \"x\" defined below as the x-axis of your plot.\n",
    "\n",
    "Experiment with what happens when you make $N$ larger and smaller. Add the answer to the following question to the variable `answer_1e`.\n",
    "\n",
    "1. Empirically, the size of $N$ does not make a huge difference.\n",
    "2. The smaller $N$ the more accurate the fit becomes\n",
    "3. The larger $N$ the more accurate the fit becomes\n",
    "\n",
    "***And don't forget to set it back to N=1000 and M=100.***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4545a804",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: Question 1e        # (required) the path to a requirements.txt file\n",
    "manual: true     # whether this is a manually-graded question\n",
    "points: 3      # how many points this question is worth; defaults to 1 internally\n",
    "check_cell: false  # whether to include a check cell after this question (for autograded questions only)\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25f287c9",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ff2129147845b03d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class Question1e:\n",
    "    mu = Question1d.mu\n",
    "    sigma = Question1d.sigma\n",
    "    toss_sum = Question1b.toss_sum \n",
    "\n",
    "    x = np.linspace(norm.ppf(0.01, N * mu, np.sqrt(N) * sigma),\n",
    "                    norm.ppf(0.99, N * mu, np.sqrt(N) * sigma),\n",
    "                    N)\n",
    "    \n",
    "    \n",
    "    # replace the answer with the correct answer to the above question\n",
    "    answer_1e = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bcf95c75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong style='color: red;'><pre style='display: inline;'>Question 1e</pre> results:</strong></p><p><strong><pre style='display: inline;'>Question 1e - 1</pre> result:</strong></p><pre>    ❌ Test case failed\n",
       "    Error at line 12 in test Question 1e:\n",
       "        assert_equal(answer_1e, 3)\n",
       "    AssertionError: 3 does not equal 0</pre>"
      ],
      "text/plain": [
       "Question 1e results:\n",
       "    Question 1e - 1 result:\n",
       "        ❌ Test case failed\n",
       "        Error at line 12 in test Question 1e:\n",
       "            assert_equal(answer_1e, 3)\n",
       "        AssertionError: 3 does not equal 0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"Question 1e\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc6a6c4",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2baf7165",
   "metadata": {},
   "source": [
    "## 2) Law of large numbers (LLN) (5 points)\n",
    "The LLN is also a key tool used by all data scientists. This principle is the basis of what is called Monte Carlo simulation. <br>\n",
    "In this paragraph, we will use this result to estimate the mean of a Poisson random variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469f5cfd",
   "metadata": {},
   "source": [
    "### 2a (1 point)\n",
    "Using the scipy library, **display the probability mass function of the Poisson distribution for $\\lambda=5$**. \n",
    "Please use the variable `x` defined below as the x-axis of your plot.\n",
    "\n",
    "You have to use the scipy library and can take a look at the example in this webpage: https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.poisson.html. \n",
    "\n",
    "**Assign the plot to the variable:** `poisson_pdf_plot`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a2abf9",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: Question 2a        # (required) the path to a requirements.txt file\n",
    "manual: true     # whether this is a manually-graded question\n",
    "points: 1      # how many points this question is worth; defaults to 1 internally\n",
    "check_cell: false  # whether to include a check cell after this question (for autograded questions only)\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33aab761",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5187511bc27d80b6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from scipy.stats import poisson # Please do not delete this line\n",
    "\n",
    "class Question2a:\n",
    "    lam = 5\n",
    "    x = np.arange(poisson.ppf(0.0001, lam),\n",
    "                  poisson.ppf(0.9999, lam))\n",
    "    ...\n",
    "    poisson_plot = ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1234c513",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong style='color: red;'><pre style='display: inline;'>Question 2a</pre> results:</strong></p><p><strong><pre style='display: inline;'>Question 2a - 1</pre> result:</strong></p><pre>    ❌ Test case failed\n",
       "    Error at line 12 in test Question 2a:\n",
       "        assert_true(0.16 <= poisson_plot[0].axes.get_ylim()[1] <= 0.19)\n",
       "    TypeError: ellipsis' object is not subscriptable</pre>"
      ],
      "text/plain": [
       "Question 2a results:\n",
       "    Question 2a - 1 result:\n",
       "        ❌ Test case failed\n",
       "        Error at line 12 in test Question 2a:\n",
       "            assert_true(0.16 <= poisson_plot[0].axes.get_ylim()[1] <= 0.19)\n",
       "        TypeError: ellipsis' object is not subscriptable"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"Question 2a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be820436",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "### 2b (2 points)\n",
    "Generate $P=10000$ independent samples from the given poisson distribution ($\\lambda = 5$) and store them in the variable `data`. Calculate the empirical mean when using the first $i = 11,12,13,...,10000$ samples from the `data` variable. *Hint:* You can use `np.cumsum()` function in numpy which calculates the cumulative sum. \n",
    "\n",
    "Make sure to divide it appropriately. Store the result in the variable `mean_est`. \n",
    "Please plot the the calculated empirical means and compare them with the true mean of the given poisson distribution (expected value) $\\lambda = 5$ using a scatter plot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7b515e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: Question 2b        # (required) the path to a requirements.txt file\n",
    "manual: true     # whether this is a manually-graded question\n",
    "points: 2      # how many points this question is worth; defaults to 1 internally\n",
    "check_cell: false  # whether to include a check cell after this question (for autograded questions only)\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5f15236",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-786d4f2af8ee5398",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'ellipsis' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_160306/2253397774.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mQuestion2b\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmean_est\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_160306/2253397774.py\u001b[0m in \u001b[0;36mQuestion2b\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mmean_est\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'ellipsis' has no len()"
     ]
    }
   ],
   "source": [
    "class Question2b:\n",
    "    P = 10000\n",
    "    data = ...\n",
    "    xs = np.arange(1, len(data) + 1)\n",
    "    mean_est = ...\n",
    "    plt.scatter(xs, ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd9a843",
   "metadata": {},
   "outputs": [],
   "source": [
    "grader.check(\"Question 2b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf31ffe",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "### 2c (2 points)\n",
    "It is rather hard to see if the empirical mean is tending to the true one. Compute the absolute error between the empirical and the true mean and store it into a variable `abs_err`. \n",
    "Plot the absolute error against the number of samples used ($x$-axis). Use a log scale (for the error)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62513e0",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: Question 2c        # (required) the path to a requirements.txt file\n",
    "manual: true     # whether this is a manually-graded question\n",
    "points: 2      # how many points this question is worth; defaults to 1 internally\n",
    "check_cell: false  # whether to include a check cell after this question (for autograded questions only)\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435f3e14",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7942b6a67e959773",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class Question2c:\n",
    "    abs_err = ...\n",
    "    plt.yscale('log')\n",
    "    err_plot = ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f026baa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "grader.check(\"Question 2c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4250d34c",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "## 3) Monte Carlo simulation (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73f7d4f",
   "metadata": {},
   "source": [
    "Did you notice that the previous plots change every time you run again the cells?\n",
    "This is because the average mean that we compute is still a random estimation. For some realization it may be close to the true mean, for other it may be far. <br>\n",
    "To get a clear conclusion, we might want to know what is happening in average, what is the average behaviour of this estimator. <br>\n",
    "<br>\n",
    "To do so, we will do a Monte Carlo simulation, i.e. reproduce the previous experiment several times and compute the average error.<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fc3759",
   "metadata": {},
   "source": [
    "### 3a (2 points):\n",
    "Compute and store the absolute error between the average means (using $i=1,2,3,... 10000$ samples as above) and the true mean. Reproduce this experiment $M_{mc}=100$ times, and compute the average error. \n",
    "Store the error in a variable `mean_abs_err`. Then plot the error. \n",
    "<br>\n",
    "Hint: for a better display, you can display ony error for $100, 101, ... 10000$ samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276a881d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: Question 3a        # (required) the path to a requirements.txt file\n",
    "manual: true     # whether this is a manually-graded question\n",
    "points: 2      # how many points this question is worth; defaults to 1 internally\n",
    "check_cell: false  # whether to include a check cell after this question (for autograded questions only)\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe2af6c",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-45781b77bc7ed15b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class Question3a:\n",
    "    M_mc = 100\n",
    "    NSamples = 10000\n",
    "    err_abs = np.zeros((M_mc,NSamples))\n",
    "    \n",
    "    ...\n",
    "    \n",
    "    mean_abs_err = ...\n",
    "    \n",
    "    start = 100\n",
    "    err_plot = plt.plot(mean_abs_err[start:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3da5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "grader.check(\"Question 3a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4483ebb",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "Notice that the plot is not changing much (as in the begining of the LLN paragraph) every time you run the code. This is (maybe) your first Monte Carlo simulation!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e76d7f",
   "metadata": {},
   "source": [
    "We saw in this notebook that by reproducing a large number of time the same experiment, we are able to estimate information about the observation, such as the distribution of the mean of some quantities. However, in many practical situations, it is impossible to have acces to a very large amount of data. In the following of the course you will see that we can construct confidence interval from the observations. This tool will be key to known either or not we can trust the result obtained with a limited amount of data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94add8e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da831855",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Question 1a results:\n",
       "    Question 1a - 1 result:\n",
       "        ❌ Test case failed\n",
       "        Error at line 13 in test Question 1a:\n",
       "              assert_equal(toss_coin_all.shape, (M, N))\n",
       "        AttributeError: ellipsis' object has no attribute 'shape\n",
       "\n",
       "Question 1b results:\n",
       "    Question 1b - 1 result:\n",
       "        ❌ Test case failed\n",
       "        Error at line 13 in test Question 1b:\n",
       "              assert_equal(toss_sum.shape[0], M)\n",
       "        AttributeError: ellipsis' object has no attribute 'shape\n",
       "\n",
       "Question 1c results:\n",
       "    Question 1c - 1 result:\n",
       "        ❌ Test case failed\n",
       "        Error at line 12 in test Question 1c:\n",
       "            area_under_curve = np.sum(density_plot[0] * (density_plot[1][1] - density_plot[1][0]))\n",
       "        TypeError: ellipsis' object is not subscriptable\n",
       "\n",
       "Question 1d results:\n",
       "    Question 1d - 1 result:\n",
       "        ❌ Test case failed\n",
       "        Error at line 12 in test Question 1d:\n",
       "            assert_true(0 <= gaussian_plot[0].axes.get_ylim()[1] <= 1)\n",
       "        TypeError: ellipsis' object is not subscriptable\n",
       "\n",
       "Question 1e results:\n",
       "    Question 1e - 1 result:\n",
       "        ❌ Test case failed\n",
       "        Error at line 12 in test Question 1e:\n",
       "            assert_equal(answer_1e, 3)\n",
       "        AssertionError: 3 does not equal 0\n",
       "\n",
       "Question 2a results:\n",
       "    Question 2a - 1 result:\n",
       "        ❌ Test case failed\n",
       "        Error at line 12 in test Question 2a:\n",
       "            assert_true(0.16 <= poisson_plot[0].axes.get_ylim()[1] <= 0.19)\n",
       "        TypeError: ellipsis' object is not subscriptable\n",
       "\n",
       "Question 2b results:\n",
       "    Question 2b - 1 result:\n",
       "        ❌ Test case failed\n",
       "        Error at line 11 in test Question 2b:\n",
       "            mean_est = env[\"Question2b\"].mean_est\n",
       "        KeyError: Question2b\n",
       "\n",
       "Question 2c results:\n",
       "    Question 2c - 1 result:\n",
       "        ❌ Test case failed\n",
       "        Error at line 11 in test Question 2c:\n",
       "            abs_err = env[\"Question2c\"].abs_err\n",
       "        KeyError: Question2c\n",
       "\n",
       "Question 3a results:\n",
       "    Question 3a - 1 result:\n",
       "        ❌ Test case failed\n",
       "        Error at line 11 in test Question 3a:\n",
       "            mean_abs_err = env[\"Question3a\"].mean_abs_err\n",
       "        KeyError: Question3a"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679c9470",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-env-pids_2023-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "07cb0c0be5d5c09ece9af089e9de2ad5458cdd62d0537c1d9b85ed67c101dd7b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
